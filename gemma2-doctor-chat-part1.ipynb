{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-15T15:08:21.767847Z","iopub.execute_input":"2024-09-15T15:08:21.768200Z","iopub.status.idle":"2024-09-15T15:10:31.222208Z","shell.execute_reply.started":"2024-09-15T15:08:21.768161Z","shell.execute_reply":"2024-09-15T15:10:31.220870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:10:31.224264Z","iopub.execute_input":"2024-09-15T15:10:31.224626Z","iopub.status.idle":"2024-09-15T15:10:51.945413Z","shell.execute_reply.started":"2024-09-15T15:10:31.224592Z","shell.execute_reply":"2024-09-15T15:10:51.944269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"hf_token\")\nlogin(token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:11:14.573653Z","iopub.execute_input":"2024-09-15T15:11:14.574380Z","iopub.status.idle":"2024-09-15T15:11:14.935523Z","shell.execute_reply.started":"2024-09-15T15:11:14.574315Z","shell.execute_reply":"2024-09-15T15:11:14.934613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Gemma-2-9b-it on HealthCare Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:14:45.667655Z","iopub.execute_input":"2024-09-15T15:14:45.668030Z","iopub.status.idle":"2024-09-15T15:14:48.601237Z","shell.execute_reply.started":"2024-09-15T15:14:45.667995Z","shell.execute_reply":"2024-09-15T15:14:48.600456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = \"google/gemma-2-9b-it\"\ndataset_name = \"lavita/ChatDoctor-HealthCareMagic-100k\"\nnew_model = \"Gemma-2-9b-it-chat-doctor\"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:15:37.419071Z","iopub.execute_input":"2024-09-15T15:15:37.419462Z","iopub.status.idle":"2024-09-15T15:15:37.426277Z","shell.execute_reply.started":"2024-09-15T15:15:37.419424Z","shell.execute_reply":"2024-09-15T15:15:37.425298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:15:51.577874Z","iopub.execute_input":"2024-09-15T15:15:51.578260Z","iopub.status.idle":"2024-09-15T15:15:51.663337Z","shell.execute_reply.started":"2024-09-15T15:15:51.578223Z","shell.execute_reply":"2024-09-15T15:15:51.662597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:16:00.281518Z","iopub.execute_input":"2024-09-15T15:16:00.281890Z","iopub.status.idle":"2024-09-15T15:16:00.288852Z","shell.execute_reply.started":"2024-09-15T15:16:00.281855Z","shell.execute_reply":"2024-09-15T15:16:00.287972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:16:09.248713Z","iopub.execute_input":"2024-09-15T15:16:09.249081Z","iopub.status.idle":"2024-09-15T15:18:54.893196Z","shell.execute_reply.started":"2024-09-15T15:16:09.249045Z","shell.execute_reply":"2024-09-15T15:18:54.892206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:19:39.234291Z","iopub.execute_input":"2024-09-15T15:19:39.234681Z","iopub.status.idle":"2024-09-15T15:19:39.244273Z","shell.execute_reply.started":"2024-09-15T15:19:39.234644Z","shell.execute_reply":"2024-09-15T15:19:39.242992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:20:08.831761Z","iopub.execute_input":"2024-09-15T15:20:08.832629Z","iopub.status.idle":"2024-09-15T15:20:10.072238Z","shell.execute_reply.started":"2024-09-15T15:20:08.832589Z","shell.execute_reply":"2024-09-15T15:20:10.071231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"system\", \"content\": row[\"instruction\"]},\n               {\"role\": \"user\", \"content\": row[\"input\"]},\n               {\"role\": \"assistant\", \"content\": row[\"output\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:20:18.368651Z","iopub.execute_input":"2024-09-15T15:20:18.369024Z","iopub.status.idle":"2024-09-15T15:20:24.518138Z","shell.execute_reply.started":"2024-09-15T15:20:18.368987Z","shell.execute_reply":"2024-09-15T15:20:24.517095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['text'][3]","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:20:56.862416Z","iopub.execute_input":"2024-09-15T15:20:56.862819Z","iopub.status.idle":"2024-09-15T15:20:56.875585Z","shell.execute_reply.started":"2024-09-15T15:20:56.862777Z","shell.execute_reply":"2024-09-15T15:20:56.874551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:21:14.119387Z","iopub.execute_input":"2024-09-15T15:21:14.120000Z","iopub.status.idle":"2024-09-15T15:21:14.142354Z","shell.execute_reply.started":"2024-09-15T15:21:14.119960Z","shell.execute_reply":"2024-09-15T15:21:14.141535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)\n# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length= 512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)\n\nmodel.config.use_cache = False\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:21:26.014789Z","iopub.execute_input":"2024-09-15T15:21:26.015162Z","iopub.status.idle":"2024-09-15T15:45:39.357597Z","shell.execute_reply.started":"2024-09-15T15:21:26.015123Z","shell.execute_reply":"2024-09-15T15:45:39.356636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:46:19.630751Z","iopub.execute_input":"2024-09-15T15:46:19.631151Z","iopub.status.idle":"2024-09-15T15:46:21.545923Z","shell.execute_reply.started":"2024-09-15T15:46:19.631112Z","shell.execute_reply":"2024-09-15T15:46:21.545018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T15:47:32.214460Z","iopub.execute_input":"2024-09-15T15:47:32.214875Z","iopub.status.idle":"2024-09-15T15:49:36.737809Z","shell.execute_reply.started":"2024-09-15T15:47:32.214839Z","shell.execute_reply":"2024-09-15T15:49:36.736831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}